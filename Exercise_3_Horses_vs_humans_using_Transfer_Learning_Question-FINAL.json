{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, # Remove dense layer before CONV layers\n",
    "                                weights = None) # Don't use default weights\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         38536192    flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            1025        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join('/tmp/training/horses')\n",
    "train_humans_dir = os.path.join('/tmp/training/humans')\n",
    "validation_horses_dir = os.path.join('/tmp/validation/horses')\n",
    "validation_humans_dir = os.path.join('/tmp/validation/humans')\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "100/100 - 82s - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.2464 - val_accuracy: 0.9595\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 20,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2,\n",
    "            callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
